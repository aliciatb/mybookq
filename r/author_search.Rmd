---
title: "myBookQ"
author: "Alicia Brown"
output: 
  flexdashboard::flex_dashboard:
    theme: yeti
    orientation: rows
    social: [ "twitter", "facebook", "linkedin"]
    source_code: "https://github.com/aliciatb/mybookq"
    favicon: favicon-q.png
runtime: shiny
---

```{r setup}
#options(shiny.sanitize.errors = T)

library(dplyr)
library(ggplot2)
library(lubridate)
library(flexdashboard)
library(httr)
library(jsonlite)
library(reshape2)
library(stringr)
library(tidyr)
library(tidytext)
library(wordcloud)
require(wesanderson)

favorite_authors <- "Louise Penny,Fred Vargas,Kate Atkinson,Nancy Atherton,Jussi Adler-Olsen,Val McDermid,Lisa Scottoline,Jacqueline Winspear,Stella Rimington,Susan Elia MacNeal"
other_authors <- "Denisa Mina,Val McDermid,Tana French,Deborah Crombie,Mike Lawson,Arnaldur Indridason,Susan Hill,Elly Griffiths,M. L. Longworth,Helene Tursten,Camilla Lackberg,David Lagercrantz,Nevada Barr"

continuing_series_words <- "returning,next,series,continue"
positive_words <- "cozy,dog,cat,village"
negative_words <- "psychological,sociopath,psychopath,serial,hunting"
```

```{r}
authorURL <- function(author){
  google_key <- 'AIzaSyAwJfF6E3x_UkuAj4ahufzJKwOHZIaEql0'
  
  # currently pulling last author, need to iterate and rbind
  author_name <- str_split(author," ", simplify = TRUE)
  
  author_first <- author_name[1]
  author_last <- author_name[2]
  
  order_by <- 'newest'
  # https://www.googleapis.com/books/v1/volumes?q=inauthor:Fred%20Vargas&langRestrict=en&orderBy=newest&printType=books&maxresults=40&prettyPrint=true&key=AIzaSyAwJfF6E3x_UkuAj4ahufzJKwOHZIaEql0
  url <- paste0("https://www.googleapis.com/books/v1/volumes?q=inauthor:",author_first,"+",author_last,"&langRestrict=en&orderBy=",order_by,"&printType=books&maxresults=40&prettyPrint=true&key=",google_key)
  url
}
```

```{r}
# Reactive data available for all shiny modules
getData <- reactive({
  # 1. Get the comma delimited string of authors from input$author_query
  
  date_from <- input$dateRange[1]
  date_to = input$dateRange[2]
  author_query <- c(input$author_query)
  
  # for debug
  # author_query <- favorite_authors
  # date_from <- Sys.Date() - 30
  # date_to <- Sys.Date() + 365
  
  authors <- str_split(author_query,",",simplify = T)
  
  books <- tibble()
  
  # 2. Get books for each author, filter by author name, combine data
  for(author in authors){
    author_url <- authorURL(author)
    data <- fromJSON(URLencode(author_url),simplifyDataFrame = TRUE)
    
    volume_info <- data$items$volumeInfo
    access_info <- data$items$accessInfo
    search_info <- data$items$searchInfo
    sale_info <- data$items$saleInfo
    
    if (is.null(volume_info) == FALSE){
      raw_data <- cbind(volume_info,sale_info,search_info) %>%
        # adding author here since results returns as list
        mutate(name = author) %>%
        # handle year and year-month dates
        mutate(
          publishedDate = case_when(
          str_length(publishedDate) == 4 ~ paste0(publishedDate,"-01-01"),
          str_length(publishedDate) == 7 ~ paste0(publishedDate,"-01"),
          TRUE ~ publishedDate)) %>%
        # filter by date control
        filter(publishedDate >= date_from) %>%
        filter(publishedDate <= date_to) %>%
        select(title,name,publishedDate,publisher,description,saleability) %>%
        mutate(description_length = str_length(description)) %>%
        arrange(desc(publishedDate))
      raw_data
      
      books <- rbind(books, raw_data)
    }
  }
  books

})
```

Inputs {.sidebar data-width=300}
-----------------------------------------------------------------------

Check for new  mysteRies!

```{r}
textAreaInput("author_query", label = "Favorite Authors:", value = favorite_authors, rows=5, resize = "vertical")
```

```{r}
  dateRangeInput('dateRange',
      label = 'Date range:',
      start = Sys.Date() - 30, end = Sys.Date() + 365
    )
```

```{r}
textAreaInput("description_positive", label = "Positive Keywords:", value = positive_words, rows=2, resize = "vertical")
```

```{r}
textAreaInput("description_negative", label = "Negative Keywords:", value = negative_words, rows=2, resize = "vertical")
```

```{r}
textAreaInput("description_continuing_series", label = "Continuing Keywords:", value = continuing_series_words, rows=2, resize = "vertical")
```

Row
-----------------------------------------------------------------------

### Available Books {.value-box}

```{r available_book_count}
renderValueBox({
  data_view <- getData()
  # for debug
  # data_view <- books
  
  if(length(data_view) > 0){
    data_view <- data_view %>%
      filter(publishedDate <= Sys.Date()) %>%
      distinct(name,title)
      
    book_count <- nrow(data_view)
    
    valueBox(book_count, 
             icon = "fa-book",
             color = "info")
  }
})
```

### Upcoming Books {.value-box}

```{r upcoming_book_count}
renderValueBox({
  data_view <- getData()
  # for debug
  # data_view <- books
  
  if(length(data_view) > 0){
    data_view <- data_view %>%
      filter(publishedDate < Sys.Date() + 30) %>%
      filter(publishedDate > Sys.Date()) %>%
      distinct(name,title)
      
    book_count <- nrow(data_view)
    
    valueBox(book_count, 
             icon = "fa-calendar",
             color = "info")
  }
})
```

### Anticipation Index {.gauge}

```{r anticipation_index}
renderGauge({
  data_view <- getData()
  
  if(length(data_view) > 0){
    data_view <- data_view
    
    # TODO: create score based on description
    books_score = 100
    
    gauge(books_score, min = 0, max = 100, symbol = '%', gaugeSectors(
      success = c(90, 100), warning = c(50, 89), danger = c(0, 49)
    ))
  }
})
```

Row {.tabset}
-----------------------------------------------------------------------

### New Books
    
```{r new_books, fig.width=18, fig.height=8}

renderTable({
  
  data_view <- getData()
  # for debug
  # data_view <- books
  
  # todo: add link https://smile.amazon.com/s?k=fred+vargas+this+poison+will+remain&i=stripbooks
   
  if(length(data_view) > 0){
    data_view %>%
      select(name, title, publishedDate) %>%
      distinct(name, title, publishedDate) %>%
      arrange(publishedDate)
  }
  else{
    paste0('No results found for ',input$author_query)
  }
}
# allow html hyperlinks
, sanitize.text.function = function(x) x)
```
  
### Upcoming Books Description Cloud  
  
```{r upcoming_books_cloud, fig.width=18, fig.height=10}
		
renderPlot({
  
  data_view <- getData()
  # for debug
  # data_view <- books
  
  if(length(data_view) > 0){
    data_view <- data_view %>%
      # only upcoming books
      filter(publishedDate > now()) 
      
    descriptions <- unnest_tokens(data_view, word, description) %>%
      anti_join(stop_words) %>%
      count(name, title, word, sort = TRUE)
  
    if(length(descriptions) > 0){
      descriptions %>%
      with(wordcloud(word, n, max.words = 100, colors=wes_palette("Darjeeling1"), scale=c(3.0,0.5), rot.per=0.1))
    }
  }
})
```

### Upcoming Book Description Sentiments

```{r upcoming_book_descriptions_sentiments, fig.width=18, fig.height=8}

# Can we judge a book by its description?

renderPlot({
  
  data_view <- getData()
  # for debug
  # data_view <- books
  
  # for later
  # book_description_sentiments <- separate_rows(data_view, description, sep = "\\.", convert = FALSE) %>%
  #   select(title, name, publisher, description) %>%
  #   drop_na(description) %>%
  #   group_by(title,name,publisher) %>%
  #   mutate(description_line = row_number()) %>%
  #   ungroup() %>%
  #   unnest_tokens(word, description) %>%
  #   inner_join(get_sentiments("bing")) %>%
  #   count(title, index = description_line %/% 80, sentiment) %>%
  #   spread(sentiment, n, fill = 0) %>%
  #   mutate(sentiment = positive - negative)
    
  if(length(data_view) > 0){
    
    book_descriptions <- separate_rows(data_view, description, sep = "\\.", convert = FALSE) %>%
      select(title, name, publisher, description) %>%
      drop_na(description) %>%
      group_by(title,name,publisher) %>%
      mutate(description_line = row_number()) %>%
      ungroup() %>%
      unnest_tokens(word, description) %>%
      inner_join(get_sentiments("bing")) %>%
      count(word, sentiment, sort = TRUE) %>%
      acast(word ~ sentiment, value.var = "n", fill = 0) %>%
      comparison.cloud(colors=wes_palette("Royal1"),
                       max.words = 100)
  }
  else{
    paste0('No results found for ',input$author_query)
  }
})
```

### Upcoming Book Descriptions

```{r upcoming_book_descriptions}

# View all results, todo: maybe limit 1 description per publisher? or perhaps average scores

renderTable({
  
  data_view <- getData()
  # for debug
  # data_view <- books
  
  if(length(data_view) > 0){
    data_view <- data_view %>%
      drop_na(description) %>%
      select(name, title, publishedDate,description) %>%
      distinct(name, title, publishedDate,description) %>%
      arrange(publishedDate)
  }
  else{
    paste0('No results found for ',input$author_query)
  }
})
```

### About

As an avid reader of mysteries, I look forward to reading the latest books from my favorite authors. In order to stay informed of release dates, mybookQ queries [google books api](https://developers.google.com/books/) to [search](https://developers.google.com/books/docs/v1/using#PerformingSearch) by author name to return the newest results.

I also would like to have a good idea on the likelihood of enjoying a book because even my most favorite author will occasionally drift into murky and less cheerful mysteries or even worse, produce a stand-alone novel that includes none of my favorite fictional friends. By performing sentiment analysis as well as checking for specific key words, I will score an Anticipation Index for all not yet released books. It would also be helpful to have a forecast for the next year in books so that I know when I must seek out new authors recommended by the Seattle Times [Adam Woog](https://www.seattletimes.com/author/adam-woog/) and now digital [Seattle Mystery Books blog](https://mysteryish.wordpress.com/).

Thanks to Julia Silge and David Robinson's awesome book  [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com)! Get it on [Amazon](https://smile.amazon.com/dp/B071K9RT9Z)!
